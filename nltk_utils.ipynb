{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import speech_recognition as sr #speech to text için\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "###########################\n",
    "\n",
    "from typing import List\n",
    "from jpype import JClass, getDefaultJVMPath, startJVM, java\n",
    "\n",
    "\n",
    "ZEMBEREK_PATH = r'C:\\Users\\oguz_zr\\Desktop\\Chatbot\\zemberek-full.jar'\n",
    "startJVM(getDefaultJVMPath(), '-ea', '-Djava.class.path=%s' % (ZEMBEREK_PATH))\n",
    "\n",
    "TurkishSentenceNormalizer= JClass('zemberek.normalization.TurkishSentenceNormalizer')\n",
    "TurkishMorphology = JClass('zemberek.morphology.TurkishMorphology')\n",
    "TurkishTokenizer = JClass('zemberek.tokenization.TurkishTokenizer')\n",
    "PerceptronNer = JClass('zemberek.ner.PerceptronNer')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(sentence):# burada alınan cümlenin yazın yanlışları veya eksik harfleri gidererek düzgün cümle çıkması hedeflenmektedir\n",
    " \n",
    "\n",
    "  \n",
    "    lookupRoot =java.nio.file.Paths.get('C:/Users/oguz_zr/Desktop/Chatbot/normalizetion/normalization')\n",
    "\n",
    "    lmFile =java.nio.file.Paths.get('C:/Users/oguz_zr/Desktop/Chatbot/normalizetion/lm/lm.2gram.slm')\n",
    "\n",
    "\n",
    "    morphology = TurkishMorphology.createWithDefaults()\n",
    "    normalizer =TurkishSentenceNormalizer(morphology,lookupRoot,lmFile)\n",
    "\n",
    "    normalize: java.util.ArrayList = (normalizer.normalize(sentence))\n",
    "\n",
    "    return normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):# cümleyi alacak fonk\n",
    "   \n",
    "    tokenzer=TurkishTokenizer.DEFAULT\n",
    "\n",
    "    token: java.util.ArrayList = (tokenzer.tokenizeToStrings(sentence))\n",
    "\n",
    "\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):# kelime kökünü bulmak için fonk\n",
    "   \n",
    "    #ZEMBEREK_PATH = r'C:\\Users\\oguz_zr\\Desktop\\Chatbot\\zemberek-full.jar'\n",
    "   # startJVM(getDefaultJVMPath(), '-ea', '-Djava.class.path=%s' % (ZEMBEREK_PATH))\n",
    "\n",
    "\n",
    "\n",
    "    morphology = TurkishMorphology.createWithDefaults()\n",
    "\n",
    "    \n",
    "    analysis: java.util.ArrayList = (\n",
    "    morphology.analyzeAndDisambiguate(word).bestAnalysis()\n",
    "    )\n",
    "    pos: List[str] = []\n",
    "    for i, analysis in enumerate(analysis, start=1):\n",
    "        f'\\nAnalysis {i}: {analysis}',\n",
    "        f'\\nPrimary POS {i}: {analysis.getPos()}'\n",
    "        f'\\nPrimary POS (Short Form) {i}: {analysis.getPos().shortForm}'\n",
    "\n",
    "        pos.append( f'{str(analysis.getLemmas()[0])}'\n",
    "    )\n",
    "  \n",
    "    \n",
    "    \n",
    "    return pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "    try:\n",
    "        \n",
    "\n",
    "        modelRoot =java.nio.file.Paths.get('ner/test-model/model')\n",
    "\n",
    "      \n",
    "        \n",
    "        morphology = TurkishMorphology.createWithDefaults()\n",
    "\n",
    "        ner = PerceptronNer.loadModel(modelRoot, morphology)\n",
    "    \n",
    "        result = ner.findNamedEntities(text)\n",
    "        namedEntities : java.util.ArrayList =(result.getNamedEntities())\n",
    "\n",
    "        ahm=str(namedEntities[0])\n",
    "        ahm=ahm.split(\" \")\n",
    "        ahm=ahm[1::]#[LOC Bursa] loc+boşlugu sileceksin bursını bak \n",
    "        t=\" \"\n",
    "        for a in ahm:\n",
    "            t=t+a+\" \"\n",
    "\n",
    "        return str(t[0:-2])\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return (\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsadsa /n dsadsad \n",
      " dasdas\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speechTotext():\n",
    "    try:\n",
    "        \n",
    "        r = sr.Recognizer()\n",
    "        print(\"--------- \\n Dinliyorum\")\n",
    "        with sr.Microphone() as source:\n",
    "            # read the audio data from the default microphone\n",
    "            audio_data = r.record(source, duration=5)\n",
    "            print(\"bekle\")\n",
    "            # convert speech to text\n",
    "            text = r.recognize_google(audio_data,language=\"tr-tr\")\n",
    "            print(\"Anladığım:: \",text, \"\\n ----------\")\n",
    "        return text\n",
    "    except:\n",
    "        print(\"Ses alamadım. Tekrar dinliyorum.\")\n",
    "        a=speechTotext()\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_word(tokenized_sentence , all_words): #gelen cümleyi kelimelerle karşılaştırıp bize belirli bir vektör döndürmeye yarıyor\n",
    "    tokenized_sentence=[stem(w) for w in tokenized_sentence]\n",
    "    bag=np.zeros(len(all_words),dtype=np.float32)\n",
    "    \n",
    "    for idx, w in enumerate(all_words):\n",
    "        if w in tokenized_sentence:\n",
    "             bag[idx]=1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence=[\"ilişkileNdiremediklerimiz\",\"Göz\",\"kaleM\"]\\nwords=[\"kalem\",\"ilişki\",\"gözlük\",\"gözlem\",\"göz\"]\\nbag=bag_of_word(sentence,words)\\nprint(bag)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"sentence=[\"ilişkileNdiremediklerimiz\",\"Göz\",\"kaleM\"]\n",
    "words=[\"kalem\",\"ilişki\",\"gözlük\",\"gözlem\",\"göz\"]\n",
    "bag=bag_of_word(sentence,words)\n",
    "print(bag)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a=\"Nasılsın\"\\nprint(a)\\na=tokenize(a)\\nprint(a)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"a=\"Nasılsın\"\n",
    "print(a)\n",
    "a=tokenize(a)\n",
    "print(a)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kelimeler = \\' ilişkileNdiremediklerimiz Gözlük GöZlem\\'\\n\\nwords=[\"kaleM\",\"ilişkileNdiremediklerimiz\",\"Gözlük\",\"GöZlem\"]\\nstemmed_word=[stem(w) for w in words]\\nprint(stemmed_word)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"kelimeler = ' ilişkileNdiremediklerimiz Gözlük GöZlem'\n",
    "\n",
    "words=[\"kaleM\",\"ilişkileNdiremediklerimiz\",\"Gözlük\",\"GöZlem\"]\n",
    "stemmed_word=[stem(w) for w in words]\n",
    "print(stemmed_word)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cumle=\"Nasılsın\"\\nprint(normalizer(cumle))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"cumle=\"Nasılsın\"\n",
    "print(normalizer(cumle))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
